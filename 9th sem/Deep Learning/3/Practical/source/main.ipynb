{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/Track1/1.csv')\n",
    "\n",
    "# balanced = pd.DataFrame()   # Balanced dataset\n",
    "# bins = 1000                 # N of bins\n",
    "# bin_n = 5000                 # N of examples to include in each bin (at most)\n",
    "\n",
    "# start = 0\n",
    "# for end in np.linspace(0, 1, num=bins):  \n",
    "#     df_range = df[(np.absolute(df.iloc[:, 3]) >= start) & (np.absolute(df.iloc[:, 3]) < end)]\n",
    "#     range_n = min(bin_n, df_range.shape[0])\n",
    "#     balanced = pd.concat([balanced, df_range.sample(range_n)])\n",
    "#     start = end\n",
    "\n",
    "# balanced.to_csv('../data/Track1/driving_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Track1', 'Track2']\n"
     ]
    }
   ],
   "source": [
    "# Path of each track\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_no = \"2\"\n",
    "\n",
    "dataroot = \"../data/Track\" + track_no + \"/\"\n",
    "ckptroot = \"../checkpoint/Track\" + track_no + \"/\"\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "test_size = 0.8\n",
    "shuffle = True\n",
    "\n",
    "epochs = 80\n",
    "start_epoch = 1\n",
    "resume = False\n",
    "\n",
    "low_prob = 0.001\n",
    "high_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDevice(datas, device):\n",
    "    \"\"\"Enable cuda.\"\"\"\n",
    "    imgs, angles = datas\n",
    "    return imgs.float().to(device), angles.float().to(device)\n",
    "\n",
    "def zoomInOut(image, scale):\n",
    "    height, width, _ = image.shape\n",
    "    center = (width // 2, height // 2)\n",
    "\n",
    "    # Zoom In\n",
    "    if scale > 1:\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        resized = cv2.resize(image, (new_width, new_height))\n",
    "        \n",
    "        start_x = max(0, center[0] - width // 2)\n",
    "        start_y = max(0, center[1] - height // 2)\n",
    "        end_x = min(new_width, center[0] + width // 2)\n",
    "        end_y = min(new_height, center[1] + height // 2)\n",
    "        \n",
    "        cropped = resized[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Ensure the cropped image has the original dimensions\n",
    "        result = np.zeros_like(image)\n",
    "        result[:cropped.shape[0], :cropped.shape[1]] = cropped\n",
    "\n",
    "    # Zoom Out\n",
    "    elif scale < 1:\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        resized = cv2.resize(image, (new_width, new_height))\n",
    "        \n",
    "        start_x = (width - new_width) // 2\n",
    "        start_y = (height - new_height) // 2\n",
    "        end_x = start_x + new_width\n",
    "        end_y = start_y + new_height\n",
    "\n",
    "        # Ensure the resized image has the original dimensions\n",
    "        result = np.zeros_like(image)\n",
    "        result[start_y:end_y, start_x:end_x] = resized\n",
    "\n",
    "    # No zoom, return original image\n",
    "    else:\n",
    "        result = image.copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "def plotHist(data_dir, col = \"steering\"):\n",
    "    # reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
    "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    # Plot histogram of all values in data_df\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data_df[col].values.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title('Histogram of All Values of ' + col)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the percentage of zero values\n",
    "    zero_percentage = (data_df[col].values.flatten() == 0).sum() / len(data_df.values.flatten()) * 100\n",
    "    print(f\"Percentage of zero values: {zero_percentage:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# def augment(dataroot, imgName, angle):\n",
    "#     \"\"\"Data augmentation.\"\"\"\n",
    "#     name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "#     current_image = cv2.imread(name)\n",
    "\n",
    "#     if current_image is None:\n",
    "#         print(name)\n",
    "    \n",
    "#     old_shape = current_image.shape\n",
    "\n",
    "#     # Crop image\n",
    "#     current_image = current_image[60:-25, :, :]\n",
    "\n",
    "#     # Randomly apply augmentation techniques\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         # Flip horizontally\n",
    "#         current_image = cv2.flip(current_image, 1)\n",
    "#         angle = angle * -1.0\n",
    "\n",
    "#     if np.random.rand() < 0.25:\n",
    "#         # Zoom\n",
    "#         scale_factor = np.random.uniform(0.8, 1.2)\n",
    "#         current_image = zoomInOut(current_image, scale_factor)\n",
    "#         # print(current_image.shape)\n",
    "\n",
    "#     if np.random.rand() < 0.25:\n",
    "#         # Pan (translation)\n",
    "#         tx = np.random.uniform(-20, 20)\n",
    "#         ty = np.random.uniform(-5, 5)\n",
    "#         translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "#         current_image = cv2.warpAffine(current_image, translation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "\n",
    "#     if np.random.rand() < 0.25:\n",
    "#         # Rotate\n",
    "#         rotation_angle = np.random.uniform(-10, 10)\n",
    "#         rotation_matrix = cv2.getRotationMatrix2D((current_image.shape[1] / 2, current_image.shape[0] / 2), rotation_angle, 1)\n",
    "#         current_image = cv2.warpAffine(current_image, rotation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "#         # angle += rotation_angle\n",
    "\n",
    "#     if np.random.rand() < 0.25:\n",
    "#         # Change brightness\n",
    "#         brightness_factor = np.random.uniform(0.5, 1.5)\n",
    "#         current_image = current_image * brightness_factor\n",
    "#         current_image = np.clip(current_image, 0, 255)\n",
    "\n",
    "#     if (old_shape != current_image.shape):\n",
    "#         print(\"Image size inconsistency detected!\")\n",
    "\n",
    "#     return current_image, angle\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def augment(dataroot, imgName, angle):\n",
    "#     \"\"\"Data augmentation.\"\"\"\n",
    "#     name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "#     current_image = cv2.imread(name)\n",
    "\n",
    "#     if current_image is None:\n",
    "#         print(name)\n",
    "\n",
    "#     # Crop image\n",
    "#     current_image = current_image[60:-25, :, :]\n",
    "\n",
    "#     old_shape = current_image.shape\n",
    "    \n",
    "#     # Randomly apply augmentation techniques\n",
    "#     if np.random.rand() < high_prob:\n",
    "#         # Flip horizontally\n",
    "#         current_image = cv2.flip(current_image, 1)\n",
    "#         angle = angle * -1.0\n",
    "\n",
    "#     if np.random.rand() < low_prob:\n",
    "#         # Zoom\n",
    "#         scale_factor = np.random.uniform(0.8, 1.2)\n",
    "#         current_image = zoomInOut(current_image, scale_factor)\n",
    "#         # print(current_image.shape)\n",
    "\n",
    "#     if np.random.rand() < low_prob:\n",
    "#         # Pan (translation)\n",
    "#         tx = np.random.uniform(-20, 20)\n",
    "#         ty = np.random.uniform(-5, 5)\n",
    "#         translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "#         current_image = cv2.warpAffine(current_image, translation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "\n",
    "#     if np.random.rand() < low_prob:\n",
    "#         # Rotate\n",
    "#         rotation_angle = np.random.uniform(-10, 10)\n",
    "#         rotation_matrix = cv2.getRotationMatrix2D((current_image.shape[1] / 2, current_image.shape[0] / 2), rotation_angle, 1)\n",
    "#         current_image = cv2.warpAffine(current_image, rotation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "#         #angle += rotation_angle\n",
    "\n",
    "#     if np.random.rand() < low_prob:\n",
    "#         # Change brightness\n",
    "#         brightness_factor = np.random.uniform(0.5, 1.5)\n",
    "#         current_image = current_image * brightness_factor\n",
    "#         current_image = np.clip(current_image, 0, 255)\n",
    "\n",
    "\n",
    "\n",
    "#     if (old_shape != current_image.shape):\n",
    "#         print(\"Image size inconsistency detected!\")\n",
    "\n",
    "#     return current_image, angle\n",
    "\n",
    "\n",
    "\n",
    "def augment(dataroot, imgName, angle):\n",
    "    \"\"\"Data augmentation.\"\"\"\n",
    "    name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "    current_image = cv2.imread(name)\n",
    "\n",
    "    if current_image is None:\n",
    "        print(name)\n",
    "\n",
    "    current_image = current_image[65:-25, :, :]\n",
    "    if np.random.rand() < high_prob:\n",
    "        current_image = cv2.flip(current_image, 1)\n",
    "        angle = angle * -1.0\n",
    "\n",
    "    return current_image, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(data_dir, test_size):\n",
    "    \"\"\"Load training data and train validation split\"\"\"\n",
    "    # reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
    "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    # smooth data signal with `savgol_filter`\n",
    "    data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
    "\n",
    "    # Divide the data into training set and validation set\n",
    "    train_len = int(test_size * data_df.shape[0])\n",
    "    valid_len = data_df.shape[0] - train_len\n",
    "    trainset, valset = data.random_split(data_df.values.tolist(),\n",
    "                                         lengths=[train_len, valid_len])\n",
    "\n",
    "    return trainset, valset\n",
    "\n",
    "trainset, valset = loadData(dataroot, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDriveCarDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataroot, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.dataroot = dataroot\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index]\n",
    "        steering_angle = float(batch_samples[3])\n",
    "\n",
    "        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n",
    "        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n",
    "        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n",
    "\n",
    "        center_img = self.transform(center_img)\n",
    "        left_img   = self.transform(left_img)\n",
    "        right_img  = self.transform(right_img)\n",
    "\n",
    "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of zero values: 6.43%\n"
     ]
    }
   ],
   "source": [
    "plotHist(dataroot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Prepare dataset ... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Prepare dataset ... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "def data_loader(dataroot,\n",
    "                trainset,\n",
    "                valset,\n",
    "                batch_size,\n",
    "                shuffle,\n",
    "                num_workers):\n",
    "    \n",
    "    transformations = transforms.Compose(\n",
    "        [transforms.Lambda(lambda x: (x / 127.5) - 1.0)])\n",
    "\n",
    "    # Load training data and validation data\n",
    "    training_set = SelfDriveCarDataset(dataroot,\n",
    "                                       trainset,\n",
    "                                       transformations)\n",
    "    trainloader = DataLoader(training_set,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             num_workers=num_workers)\n",
    "\n",
    "    validation_set = SelfDriveCarDataset(dataroot,\n",
    "                                         valset,\n",
    "                                         transformations)\n",
    "    valloader = DataLoader(validation_set,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           num_workers=num_workers)\n",
    "\n",
    "    return trainloader, valloader\n",
    "\n",
    "\n",
    "trainloader, validationloader = data_loader(dataroot,\n",
    "                                            trainset, valset,\n",
    "                                            batch_size,\n",
    "                                            shuffle,\n",
    "                                            num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Initialize model ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Initializing model done ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "class SelfDriveCarNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SelfDriveCarNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(24, 36, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(36, 48, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(48, 64, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features = 64 * 2 * 33, out_features = 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features = 100, out_features = 50),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features = 50, out_features = 10),\n",
    "            nn.Linear(in_features = 10, out_features = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        input = input.view(input.size(0), 3, 70, 320)\n",
    "        output = self.conv_layers(input)\n",
    "        # print(output.shape)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Define model\n",
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Initialize model ..... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "model = SelfDriveCarNetwork()\n",
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Initializing model done ..... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr = lr,\n",
    "                       weight_decay = weight_decay)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# learning rate scheduler\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
    "\n",
    "# transfer to gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Load checkpoint ..... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    checkpoint = torch.load(\"../checkpoint/Track1/both-nvidia-model-41.h5\",\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 ckptroot,\n",
    "                 model,\n",
    "                 device,\n",
    "                 epochs,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 start_epoch,\n",
    "                 trainloader,\n",
    "                 validationloader):\n",
    "        super(Trainer, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.ckptroot = ckptroot\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.start_epoch = start_epoch\n",
    "        self.trainloader = trainloader\n",
    "        self.validationloader = validationloader\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training process.\"\"\"\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Training\n",
    "            train_loss = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
    "                # Transfer to GPU\n",
    "                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                    lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                # Model computations\n",
    "                self.optimizer.zero_grad()\n",
    "                datas = [centers, lefts, rights]\n",
    "                for data in datas:\n",
    "                    imgs, angles = data\n",
    "                    # print(\"training image: \", imgs.shape)\n",
    "                    outputs = self.model(imgs)\n",
    "                    loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    train_loss += loss.data.item()\n",
    "\n",
    "                if local_batch % 100 == 0:\n",
    "\n",
    "                    print(\"â™¯ Epoch: {}/{}    |    ğŸ’²Loss: {}\".format(epoch, epochs, train_loss / (local_batch + 1)))\n",
    "            \n",
    "            # Adjust learning rate after optimizer step\n",
    "            # self.scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.set_grad_enabled(False):\n",
    "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
    "                    # Transfer to GPU\n",
    "                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                        lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                    # Model computations\n",
    "                    self.optimizer.zero_grad()\n",
    "                    datas = [centers, lefts, rights]\n",
    "                    for data in datas:\n",
    "                        imgs, angles = data\n",
    "                        outputs = self.model(imgs)\n",
    "                        loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "\n",
    "                        valid_loss += loss.data.item()\n",
    "\n",
    "                    if local_batch % 100 == 0:\n",
    "                        print(\"ğŸ’°Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
    "\n",
    "            print()\n",
    "            # Save model\n",
    "            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n",
    "\n",
    "                state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'scheduler': self.scheduler.state_dict(),\n",
    "                }\n",
    "\n",
    "                self.saveCheckpoint(state)\n",
    "\n",
    "    def saveCheckpoint(self, state):\n",
    "        \"\"\"Save checkpoint.\"\"\"\n",
    "        print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Save checkpoint ..... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "        if not os.path.exists(self.ckptroot):\n",
    "            os.makedirs(self.ckptroot)\n",
    "\n",
    "        torch.save(state, self.ckptroot + 'Track' + str(track_no) + '-{}.h5'.format(state['epoch']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Start training ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™¯ Epoch: 1/80    |    ğŸ’²Loss: 1.0789968371391296\n",
      "â™¯ Epoch: 1/80    |    ğŸ’²Loss: 0.5891211275564562\n",
      "â™¯ Epoch: 1/80    |    ğŸ’²Loss: 0.5678367005355323\n",
      "â™¯ Epoch: 1/80    |    ğŸ’²Loss: 0.546461803003205\n",
      "â™¯ Epoch: 1/80    |    ğŸ’²Loss: 0.535653780802081\n",
      "ğŸ’°Validation Loss: 0.42492612823843956\n",
      "ğŸ’°Validation Loss: 0.4915510042764173\n",
      "\n",
      "â™¯ Epoch: 2/80    |    ğŸ’²Loss: 0.49787240475416183\n",
      "â™¯ Epoch: 2/80    |    ğŸ’²Loss: 0.4863513311242113\n",
      "â™¯ Epoch: 2/80    |    ğŸ’²Loss: 0.47084528680390386\n",
      "â™¯ Epoch: 2/80    |    ğŸ’²Loss: 0.4751047962020303\n",
      "â™¯ Epoch: 2/80    |    ğŸ’²Loss: 0.4705694856962881\n",
      "ğŸ’°Validation Loss: 0.5789471790194511\n",
      "ğŸ’°Validation Loss: 0.44787647787223356\n",
      "\n",
      "â™¯ Epoch: 3/80    |    ğŸ’²Loss: 0.4365415498614311\n",
      "â™¯ Epoch: 3/80    |    ğŸ’²Loss: 0.4358820178831863\n",
      "â™¯ Epoch: 3/80    |    ğŸ’²Loss: 0.4291780297899276\n",
      "â™¯ Epoch: 3/80    |    ğŸ’²Loss: 0.42799127191626946\n",
      "â™¯ Epoch: 3/80    |    ğŸ’²Loss: 0.4278092011623549\n",
      "ğŸ’°Validation Loss: 0.43871352076530457\n",
      "ğŸ’°Validation Loss: 0.4144937840502451\n",
      "\n",
      "â™¯ Epoch: 4/80    |    ğŸ’²Loss: 0.43078170344233513\n",
      "â™¯ Epoch: 4/80    |    ğŸ’²Loss: 0.422631655183464\n",
      "â™¯ Epoch: 4/80    |    ğŸ’²Loss: 0.41541461752199416\n",
      "â™¯ Epoch: 4/80    |    ğŸ’²Loss: 0.40859234850371\n",
      "â™¯ Epoch: 4/80    |    ğŸ’²Loss: 0.40602249556924785\n",
      "ğŸ’°Validation Loss: 0.35175948590040207\n",
      "ğŸ’°Validation Loss: 0.39837193334161647\n",
      "\n",
      "â™¯ Epoch: 5/80    |    ğŸ’²Loss: 0.41921862959861755\n",
      "â™¯ Epoch: 5/80    |    ğŸ’²Loss: 0.37994915136311314\n",
      "â™¯ Epoch: 5/80    |    ğŸ’²Loss: 0.3887161964837888\n",
      "â™¯ Epoch: 5/80    |    ğŸ’²Loss: 0.3906201395976583\n",
      "â™¯ Epoch: 5/80    |    ğŸ’²Loss: 0.38865484570866066\n",
      "ğŸ’°Validation Loss: 0.35202987864613533\n",
      "ğŸ’°Validation Loss: 0.3930133766688333\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 6/80    |    ğŸ’²Loss: 0.3034930154681206\n",
      "â™¯ Epoch: 6/80    |    ğŸ’²Loss: 0.39059937785905186\n",
      "â™¯ Epoch: 6/80    |    ğŸ’²Loss: 0.38368446023124664\n",
      "â™¯ Epoch: 6/80    |    ğŸ’²Loss: 0.3825175384820696\n",
      "â™¯ Epoch: 6/80    |    ğŸ’²Loss: 0.37724907276339065\n",
      "ğŸ’°Validation Loss: 0.5646967887878418\n",
      "ğŸ’°Validation Loss: 0.3624236583156456\n",
      "\n",
      "â™¯ Epoch: 7/80    |    ğŸ’²Loss: 0.44387149065732956\n",
      "â™¯ Epoch: 7/80    |    ğŸ’²Loss: 0.36004175420961165\n",
      "â™¯ Epoch: 7/80    |    ğŸ’²Loss: 0.3609032971385996\n",
      "â™¯ Epoch: 7/80    |    ğŸ’²Loss: 0.3615447235637131\n",
      "â™¯ Epoch: 7/80    |    ğŸ’²Loss: 0.3639121910794046\n",
      "ğŸ’°Validation Loss: 0.3351053148508072\n",
      "ğŸ’°Validation Loss: 0.3752197773739843\n",
      "\n",
      "â™¯ Epoch: 8/80    |    ğŸ’²Loss: 0.36448921263217926\n",
      "â™¯ Epoch: 8/80    |    ğŸ’²Loss: 0.35376251748956666\n",
      "â™¯ Epoch: 8/80    |    ğŸ’²Loss: 0.35660953401814943\n",
      "â™¯ Epoch: 8/80    |    ğŸ’²Loss: 0.3586861698940842\n",
      "â™¯ Epoch: 8/80    |    ğŸ’²Loss: 0.35755529260713415\n",
      "ğŸ’°Validation Loss: 0.2790077142417431\n",
      "ğŸ’°Validation Loss: 0.3568301304695335\n",
      "\n",
      "â™¯ Epoch: 9/80    |    ğŸ’²Loss: 0.2827504277229309\n",
      "â™¯ Epoch: 9/80    |    ğŸ’²Loss: 0.3540960135546946\n",
      "â™¯ Epoch: 9/80    |    ğŸ’²Loss: 0.35409864523814094\n",
      "â™¯ Epoch: 9/80    |    ğŸ’²Loss: 0.3527277488806022\n",
      "â™¯ Epoch: 9/80    |    ğŸ’²Loss: 0.35114311619180993\n",
      "ğŸ’°Validation Loss: 0.49908018112182617\n",
      "ğŸ’°Validation Loss: 0.346133878454566\n",
      "\n",
      "â™¯ Epoch: 10/80    |    ğŸ’²Loss: 0.2901514284312725\n",
      "â™¯ Epoch: 10/80    |    ğŸ’²Loss: 0.3418299653336848\n",
      "â™¯ Epoch: 10/80    |    ğŸ’²Loss: 0.3449160567952774\n",
      "â™¯ Epoch: 10/80    |    ğŸ’²Loss: 0.3397885741003823\n",
      "â™¯ Epoch: 10/80    |    ğŸ’²Loss: 0.3401596484580391\n",
      "ğŸ’°Validation Loss: 0.2970487028360367\n",
      "ğŸ’°Validation Loss: 0.34879861028846537\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 11/80    |    ğŸ’²Loss: 0.2943701967597008\n",
      "â™¯ Epoch: 11/80    |    ğŸ’²Loss: 0.3271487408345289\n",
      "â™¯ Epoch: 11/80    |    ğŸ’²Loss: 0.32911664943456354\n",
      "â™¯ Epoch: 11/80    |    ğŸ’²Loss: 0.33294976196341536\n",
      "â™¯ Epoch: 11/80    |    ğŸ’²Loss: 0.335455759528309\n",
      "ğŸ’°Validation Loss: 0.311991598457098\n",
      "ğŸ’°Validation Loss: 0.33830039221608993\n",
      "\n",
      "â™¯ Epoch: 12/80    |    ğŸ’²Loss: 0.3201151490211487\n",
      "â™¯ Epoch: 12/80    |    ğŸ’²Loss: 0.32729581830156323\n",
      "â™¯ Epoch: 12/80    |    ğŸ’²Loss: 0.32970053493161106\n",
      "â™¯ Epoch: 12/80    |    ğŸ’²Loss: 0.32727387026447397\n",
      "â™¯ Epoch: 12/80    |    ğŸ’²Loss: 0.32765180986383907\n",
      "ğŸ’°Validation Loss: 0.29080547019839287\n",
      "ğŸ’°Validation Loss: 0.339041988872508\n",
      "\n",
      "â™¯ Epoch: 13/80    |    ğŸ’²Loss: 0.4032275378704071\n",
      "â™¯ Epoch: 13/80    |    ğŸ’²Loss: 0.3231710991315027\n",
      "â™¯ Epoch: 13/80    |    ğŸ’²Loss: 0.3226171084193151\n",
      "â™¯ Epoch: 13/80    |    ğŸ’²Loss: 0.322728405561162\n",
      "â™¯ Epoch: 13/80    |    ğŸ’²Loss: 0.32314741122826673\n",
      "ğŸ’°Validation Loss: 0.2827373594045639\n",
      "ğŸ’°Validation Loss: 0.3239994660425599\n",
      "\n",
      "â™¯ Epoch: 14/80    |    ğŸ’²Loss: 0.33751168102025986\n",
      "â™¯ Epoch: 14/80    |    ğŸ’²Loss: 0.32040216755306367\n",
      "â™¯ Epoch: 14/80    |    ğŸ’²Loss: 0.31815888930056524\n",
      "â™¯ Epoch: 14/80    |    ğŸ’²Loss: 0.3186076460499007\n",
      "â™¯ Epoch: 14/80    |    ğŸ’²Loss: 0.31738791068054345\n",
      "ğŸ’°Validation Loss: 0.38295928388834\n",
      "ğŸ’°Validation Loss: 0.3211564188362053\n",
      "\n",
      "â™¯ Epoch: 15/80    |    ğŸ’²Loss: 0.2747404985129833\n",
      "â™¯ Epoch: 15/80    |    ğŸ’²Loss: 0.3029673577719691\n",
      "â™¯ Epoch: 15/80    |    ğŸ’²Loss: 0.3052987331218684\n",
      "â™¯ Epoch: 15/80    |    ğŸ’²Loss: 0.3071843074492343\n",
      "â™¯ Epoch: 15/80    |    ğŸ’²Loss: 0.3069361673802732\n",
      "ğŸ’°Validation Loss: 0.3222102075815201\n",
      "ğŸ’°Validation Loss: 0.33365019645062416\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 16/80    |    ğŸ’²Loss: 0.26308485865592957\n",
      "â™¯ Epoch: 16/80    |    ğŸ’²Loss: 0.3035302709898736\n",
      "â™¯ Epoch: 16/80    |    ğŸ’²Loss: 0.30434099260940034\n",
      "â™¯ Epoch: 16/80    |    ğŸ’²Loss: 0.304581132339951\n",
      "â™¯ Epoch: 16/80    |    ğŸ’²Loss: 0.30313628758454786\n",
      "ğŸ’°Validation Loss: 0.33816345036029816\n",
      "ğŸ’°Validation Loss: 0.3216714423776853\n",
      "\n",
      "â™¯ Epoch: 17/80    |    ğŸ’²Loss: 0.3024689704179764\n",
      "â™¯ Epoch: 17/80    |    ğŸ’²Loss: 0.29769571569960307\n",
      "â™¯ Epoch: 17/80    |    ğŸ’²Loss: 0.29938186217673973\n",
      "â™¯ Epoch: 17/80    |    ğŸ’²Loss: 0.3007283070653776\n",
      "â™¯ Epoch: 17/80    |    ğŸ’²Loss: 0.3008462832636778\n",
      "ğŸ’°Validation Loss: 0.2942308150231838\n",
      "ğŸ’°Validation Loss: 0.3192213539698041\n",
      "\n",
      "â™¯ Epoch: 18/80    |    ğŸ’²Loss: 0.2774704732000828\n",
      "â™¯ Epoch: 18/80    |    ğŸ’²Loss: 0.2949922949370771\n",
      "â™¯ Epoch: 18/80    |    ğŸ’²Loss: 0.2973026710085163\n",
      "â™¯ Epoch: 18/80    |    ğŸ’²Loss: 0.29678809179915144\n",
      "â™¯ Epoch: 18/80    |    ğŸ’²Loss: 0.2979724119113122\n",
      "ğŸ’°Validation Loss: 0.3312532529234886\n",
      "ğŸ’°Validation Loss: 0.3164221855931648\n",
      "\n",
      "â™¯ Epoch: 19/80    |    ğŸ’²Loss: 0.35118722170591354\n",
      "â™¯ Epoch: 19/80    |    ğŸ’²Loss: 0.2931237990718962\n",
      "â™¯ Epoch: 19/80    |    ğŸ’²Loss: 0.2885333219292893\n",
      "â™¯ Epoch: 19/80    |    ğŸ’²Loss: 0.28995121205442176\n",
      "â™¯ Epoch: 19/80    |    ğŸ’²Loss: 0.2896787686194491\n",
      "ğŸ’°Validation Loss: 0.35526639223098755\n",
      "ğŸ’°Validation Loss: 0.3128999690202498\n",
      "\n",
      "â™¯ Epoch: 20/80    |    ğŸ’²Loss: 0.28284383565187454\n",
      "â™¯ Epoch: 20/80    |    ğŸ’²Loss: 0.2804551485298884\n",
      "â™¯ Epoch: 20/80    |    ğŸ’²Loss: 0.2852101875515423\n",
      "â™¯ Epoch: 20/80    |    ğŸ’²Loss: 0.286211345901719\n",
      "â™¯ Epoch: 20/80    |    ğŸ’²Loss: 0.288232609104746\n",
      "ğŸ’°Validation Loss: 0.26343265175819397\n",
      "ğŸ’°Validation Loss: 0.31191365714046626\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 21/80    |    ğŸ’²Loss: 0.31691350787878036\n",
      "â™¯ Epoch: 21/80    |    ğŸ’²Loss: 0.27456129875292284\n",
      "â™¯ Epoch: 21/80    |    ğŸ’²Loss: 0.27679063381617935\n",
      "â™¯ Epoch: 21/80    |    ğŸ’²Loss: 0.2803767365326121\n",
      "â™¯ Epoch: 21/80    |    ğŸ’²Loss: 0.27997000342202455\n",
      "ğŸ’°Validation Loss: 0.2903333753347397\n",
      "ğŸ’°Validation Loss: 0.3087592188195132\n",
      "\n",
      "â™¯ Epoch: 22/80    |    ğŸ’²Loss: 0.3526230603456497\n",
      "â™¯ Epoch: 22/80    |    ğŸ’²Loss: 0.26842618567666204\n",
      "â™¯ Epoch: 22/80    |    ğŸ’²Loss: 0.2735321112069769\n",
      "â™¯ Epoch: 22/80    |    ğŸ’²Loss: 0.2754332126115149\n",
      "â™¯ Epoch: 22/80    |    ğŸ’²Loss: 0.2752375617446819\n",
      "ğŸ’°Validation Loss: 0.2280397154390812\n",
      "ğŸ’°Validation Loss: 0.30342300855877374\n",
      "\n",
      "â™¯ Epoch: 23/80    |    ğŸ’²Loss: 0.2827387824654579\n",
      "â™¯ Epoch: 23/80    |    ğŸ’²Loss: 0.2679511529789998\n",
      "â™¯ Epoch: 23/80    |    ğŸ’²Loss: 0.27345360625553783\n",
      "â™¯ Epoch: 23/80    |    ğŸ’²Loss: 0.27221459294499156\n",
      "â™¯ Epoch: 23/80    |    ğŸ’²Loss: 0.273771970265747\n",
      "ğŸ’°Validation Loss: 0.2752342261373997\n",
      "ğŸ’°Validation Loss: 0.3012013757914895\n",
      "\n",
      "â™¯ Epoch: 24/80    |    ğŸ’²Loss: 0.25961223244667053\n",
      "â™¯ Epoch: 24/80    |    ğŸ’²Loss: 0.2679650087167721\n",
      "â™¯ Epoch: 24/80    |    ğŸ’²Loss: 0.26846305873078197\n",
      "â™¯ Epoch: 24/80    |    ğŸ’²Loss: 0.26915134331737445\n",
      "â™¯ Epoch: 24/80    |    ğŸ’²Loss: 0.2694920315929779\n",
      "ğŸ’°Validation Loss: 0.279324546456337\n",
      "ğŸ’°Validation Loss: 0.30837977749507617\n",
      "\n",
      "â™¯ Epoch: 25/80    |    ğŸ’²Loss: 0.3267845958471298\n",
      "â™¯ Epoch: 25/80    |    ğŸ’²Loss: 0.2630139473862577\n",
      "â™¯ Epoch: 25/80    |    ğŸ’²Loss: 0.26338821665305107\n",
      "â™¯ Epoch: 25/80    |    ğŸ’²Loss: 0.2635515207034904\n",
      "â™¯ Epoch: 25/80    |    ğŸ’²Loss: 0.26443159865433735\n",
      "ğŸ’°Validation Loss: 0.2654334530234337\n",
      "ğŸ’°Validation Loss: 0.2925746343882367\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 26/80    |    ğŸ’²Loss: 0.2392771691083908\n",
      "â™¯ Epoch: 26/80    |    ğŸ’²Loss: 0.26215009985141235\n",
      "â™¯ Epoch: 26/80    |    ğŸ’²Loss: 0.2640311137323652\n",
      "â™¯ Epoch: 26/80    |    ğŸ’²Loss: 0.2639965620572583\n",
      "â™¯ Epoch: 26/80    |    ğŸ’²Loss: 0.26281199465387334\n",
      "ğŸ’°Validation Loss: 0.41642242670059204\n",
      "ğŸ’°Validation Loss: 0.29831558980490314\n",
      "\n",
      "â™¯ Epoch: 27/80    |    ğŸ’²Loss: 0.25468848645687103\n",
      "â™¯ Epoch: 27/80    |    ğŸ’²Loss: 0.25579902462403076\n",
      "â™¯ Epoch: 27/80    |    ğŸ’²Loss: 0.258098004594334\n",
      "â™¯ Epoch: 27/80    |    ğŸ’²Loss: 0.25681747907333297\n",
      "â™¯ Epoch: 27/80    |    ğŸ’²Loss: 0.257168566652497\n",
      "ğŸ’°Validation Loss: 0.3489441052079201\n",
      "ğŸ’°Validation Loss: 0.29201861640604415\n",
      "\n",
      "â™¯ Epoch: 28/80    |    ğŸ’²Loss: 0.28305579721927643\n",
      "â™¯ Epoch: 28/80    |    ğŸ’²Loss: 0.2538606888144323\n",
      "â™¯ Epoch: 28/80    |    ğŸ’²Loss: 0.254441469277612\n",
      "â™¯ Epoch: 28/80    |    ğŸ’²Loss: 0.25467298904811325\n",
      "â™¯ Epoch: 28/80    |    ğŸ’²Loss: 0.255462278607313\n",
      "ğŸ’°Validation Loss: 0.3742791712284088\n",
      "ğŸ’°Validation Loss: 0.29547197240782846\n",
      "\n",
      "â™¯ Epoch: 29/80    |    ğŸ’²Loss: 0.30686865746974945\n",
      "â™¯ Epoch: 29/80    |    ğŸ’²Loss: 0.2537425090973773\n",
      "â™¯ Epoch: 29/80    |    ğŸ’²Loss: 0.2524027126002593\n",
      "â™¯ Epoch: 29/80    |    ğŸ’²Loss: 0.2511879000874651\n",
      "â™¯ Epoch: 29/80    |    ğŸ’²Loss: 0.2539107010576716\n",
      "ğŸ’°Validation Loss: 0.29522908106446266\n",
      "ğŸ’°Validation Loss: 0.29685040469290597\n",
      "\n",
      "â™¯ Epoch: 30/80    |    ğŸ’²Loss: 0.2651873007416725\n",
      "â™¯ Epoch: 30/80    |    ğŸ’²Loss: 0.24165000803399794\n",
      "â™¯ Epoch: 30/80    |    ğŸ’²Loss: 0.23730775110182625\n",
      "â™¯ Epoch: 30/80    |    ğŸ’²Loss: 0.23652395468972548\n",
      "â™¯ Epoch: 30/80    |    ğŸ’²Loss: 0.23436220162350713\n",
      "ğŸ’°Validation Loss: 0.24622299522161484\n",
      "ğŸ’°Validation Loss: 0.2731948036626719\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 31/80    |    ğŸ’²Loss: 0.23698848113417625\n",
      "â™¯ Epoch: 31/80    |    ğŸ’²Loss: 0.2291500301441491\n",
      "â™¯ Epoch: 31/80    |    ğŸ’²Loss: 0.22857534314102645\n",
      "â™¯ Epoch: 31/80    |    ğŸ’²Loss: 0.22906288982019374\n",
      "â™¯ Epoch: 31/80    |    ğŸ’²Loss: 0.22941462002332297\n",
      "ğŸ’°Validation Loss: 0.29768267273902893\n",
      "ğŸ’°Validation Loss: 0.2801923789268378\n",
      "\n",
      "â™¯ Epoch: 32/80    |    ğŸ’²Loss: 0.24195203185081482\n",
      "â™¯ Epoch: 32/80    |    ğŸ’²Loss: 0.2283185056991654\n",
      "â™¯ Epoch: 32/80    |    ğŸ’²Loss: 0.2258489012616265\n",
      "â™¯ Epoch: 32/80    |    ğŸ’²Loss: 0.22582407919782835\n",
      "â™¯ Epoch: 32/80    |    ğŸ’²Loss: 0.22595549916193594\n",
      "ğŸ’°Validation Loss: 0.31717611104249954\n",
      "ğŸ’°Validation Loss: 0.2774381575054756\n",
      "\n",
      "â™¯ Epoch: 33/80    |    ğŸ’²Loss: 0.2699716091156006\n",
      "â™¯ Epoch: 33/80    |    ğŸ’²Loss: 0.22691286241838543\n",
      "â™¯ Epoch: 33/80    |    ğŸ’²Loss: 0.22354027337918234\n",
      "â™¯ Epoch: 33/80    |    ğŸ’²Loss: 0.22505667412721636\n",
      "â™¯ Epoch: 33/80    |    ğŸ’²Loss: 0.22546738778192207\n",
      "ğŸ’°Validation Loss: 0.2500731274485588\n",
      "ğŸ’°Validation Loss: 0.27197661787492805\n",
      "\n",
      "â™¯ Epoch: 34/80    |    ğŸ’²Loss: 0.19609391875565052\n",
      "â™¯ Epoch: 34/80    |    ğŸ’²Loss: 0.2237851251248676\n",
      "â™¯ Epoch: 34/80    |    ğŸ’²Loss: 0.22562076640662862\n",
      "â™¯ Epoch: 34/80    |    ğŸ’²Loss: 0.2240283051536626\n",
      "â™¯ Epoch: 34/80    |    ğŸ’²Loss: 0.22286604881110111\n",
      "ğŸ’°Validation Loss: 0.3536422625184059\n",
      "ğŸ’°Validation Loss: 0.27231843066908934\n",
      "\n",
      "â™¯ Epoch: 35/80    |    ğŸ’²Loss: 0.25131698697805405\n",
      "â™¯ Epoch: 35/80    |    ğŸ’²Loss: 0.22449143500168725\n",
      "â™¯ Epoch: 35/80    |    ğŸ’²Loss: 0.2242180415619146\n",
      "â™¯ Epoch: 35/80    |    ğŸ’²Loss: 0.22429143429804976\n",
      "â™¯ Epoch: 35/80    |    ğŸ’²Loss: 0.22423718845764376\n",
      "ğŸ’°Validation Loss: 0.21415042132139206\n",
      "ğŸ’°Validation Loss: 0.27127675046351285\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 36/80    |    ğŸ’²Loss: 0.226675882935524\n",
      "â™¯ Epoch: 36/80    |    ğŸ’²Loss: 0.21739624029412719\n",
      "â™¯ Epoch: 36/80    |    ğŸ’²Loss: 0.22055212854968376\n",
      "â™¯ Epoch: 36/80    |    ğŸ’²Loss: 0.2205144670170011\n",
      "â™¯ Epoch: 36/80    |    ğŸ’²Loss: 0.22062043104311474\n",
      "ğŸ’°Validation Loss: 0.2574428394436836\n",
      "ğŸ’°Validation Loss: 0.27547642042731296\n",
      "\n",
      "â™¯ Epoch: 37/80    |    ğŸ’²Loss: 0.24259799718856812\n",
      "â™¯ Epoch: 37/80    |    ğŸ’²Loss: 0.22457681931924112\n",
      "â™¯ Epoch: 37/80    |    ğŸ’²Loss: 0.2235710823176364\n",
      "â™¯ Epoch: 37/80    |    ğŸ’²Loss: 0.22254210818818834\n",
      "â™¯ Epoch: 37/80    |    ğŸ’²Loss: 0.22066981609251138\n",
      "ğŸ’°Validation Loss: 0.2931225150823593\n",
      "ğŸ’°Validation Loss: 0.2673967040448201\n",
      "\n",
      "â™¯ Epoch: 38/80    |    ğŸ’²Loss: 0.2385665401816368\n",
      "â™¯ Epoch: 38/80    |    ğŸ’²Loss: 0.21446369783860622\n",
      "â™¯ Epoch: 38/80    |    ğŸ’²Loss: 0.2166371186592834\n",
      "â™¯ Epoch: 38/80    |    ğŸ’²Loss: 0.2181906955520873\n",
      "â™¯ Epoch: 38/80    |    ğŸ’²Loss: 0.2193370121496351\n",
      "ğŸ’°Validation Loss: 0.28602180257439613\n",
      "ğŸ’°Validation Loss: 0.2705413180467959\n",
      "\n",
      "â™¯ Epoch: 39/80    |    ğŸ’²Loss: 0.179477971047163\n",
      "â™¯ Epoch: 39/80    |    ğŸ’²Loss: 0.2179382776122282\n",
      "â™¯ Epoch: 39/80    |    ğŸ’²Loss: 0.21898821261317575\n",
      "â™¯ Epoch: 39/80    |    ğŸ’²Loss: 0.21920723584403232\n",
      "â™¯ Epoch: 39/80    |    ğŸ’²Loss: 0.21957213054654975\n",
      "ğŸ’°Validation Loss: 0.28684407472610474\n",
      "ğŸ’°Validation Loss: 0.2736136311536083\n",
      "\n",
      "â™¯ Epoch: 40/80    |    ğŸ’²Loss: 0.1973193921148777\n",
      "â™¯ Epoch: 40/80    |    ğŸ’²Loss: 0.2144677861787305\n",
      "â™¯ Epoch: 40/80    |    ğŸ’²Loss: 0.21785057107199782\n",
      "â™¯ Epoch: 40/80    |    ğŸ’²Loss: 0.2177865304968682\n",
      "â™¯ Epoch: 40/80    |    ğŸ’²Loss: 0.21988529409572222\n",
      "ğŸ’°Validation Loss: 0.290727686136961\n",
      "ğŸ’°Validation Loss: 0.271963210656575\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 41/80    |    ğŸ’²Loss: 0.24188537895679474\n",
      "â™¯ Epoch: 41/80    |    ğŸ’²Loss: 0.21371608616618237\n",
      "â™¯ Epoch: 41/80    |    ğŸ’²Loss: 0.2145392731184242\n",
      "â™¯ Epoch: 41/80    |    ğŸ’²Loss: 0.2155356690027686\n",
      "â™¯ Epoch: 41/80    |    ğŸ’²Loss: 0.2168706575840563\n",
      "ğŸ’°Validation Loss: 0.2684746980667114\n",
      "ğŸ’°Validation Loss: 0.2712864094035755\n",
      "\n",
      "â™¯ Epoch: 42/80    |    ğŸ’²Loss: 0.1756697278469801\n",
      "â™¯ Epoch: 42/80    |    ğŸ’²Loss: 0.21823724106618084\n",
      "â™¯ Epoch: 42/80    |    ğŸ’²Loss: 0.2191868171429456\n",
      "â™¯ Epoch: 42/80    |    ğŸ’²Loss: 0.21787354563891986\n",
      "â™¯ Epoch: 42/80    |    ğŸ’²Loss: 0.21743506493924786\n",
      "ğŸ’°Validation Loss: 0.2807992547750473\n",
      "ğŸ’°Validation Loss: 0.2711956576250567\n",
      "\n",
      "â™¯ Epoch: 43/80    |    ğŸ’²Loss: 0.19946749322116375\n",
      "â™¯ Epoch: 43/80    |    ğŸ’²Loss: 0.2098468982679124\n",
      "â™¯ Epoch: 43/80    |    ğŸ’²Loss: 0.21316178575324923\n",
      "â™¯ Epoch: 43/80    |    ğŸ’²Loss: 0.21523712442080148\n",
      "â™¯ Epoch: 43/80    |    ğŸ’²Loss: 0.21542062068084009\n",
      "ğŸ’°Validation Loss: 0.32747982442379\n",
      "ğŸ’°Validation Loss: 0.269970269689318\n",
      "\n",
      "â™¯ Epoch: 44/80    |    ğŸ’²Loss: 0.19494874589145184\n",
      "â™¯ Epoch: 44/80    |    ğŸ’²Loss: 0.21248947120834105\n",
      "â™¯ Epoch: 44/80    |    ğŸ’²Loss: 0.2152543659530469\n",
      "â™¯ Epoch: 44/80    |    ğŸ’²Loss: 0.21737734998492803\n",
      "â™¯ Epoch: 44/80    |    ğŸ’²Loss: 0.21627157875696695\n",
      "ğŸ’°Validation Loss: 0.24140388146042824\n",
      "ğŸ’°Validation Loss: 0.26488354206454046\n",
      "\n",
      "â™¯ Epoch: 45/80    |    ğŸ’²Loss: 0.23264973983168602\n",
      "â™¯ Epoch: 45/80    |    ğŸ’²Loss: 0.2125098343274676\n",
      "â™¯ Epoch: 45/80    |    ğŸ’²Loss: 0.21259951722154866\n",
      "â™¯ Epoch: 45/80    |    ğŸ’²Loss: 0.21437085020755017\n",
      "â™¯ Epoch: 45/80    |    ğŸ’²Loss: 0.21378114512259896\n",
      "ğŸ’°Validation Loss: 0.26579026132822037\n",
      "ğŸ’°Validation Loss: 0.2705269027685765\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 46/80    |    ğŸ’²Loss: 0.19480472430586815\n",
      "â™¯ Epoch: 46/80    |    ğŸ’²Loss: 0.21395295192625854\n",
      "â™¯ Epoch: 46/80    |    ğŸ’²Loss: 0.2123872942073428\n",
      "â™¯ Epoch: 46/80    |    ğŸ’²Loss: 0.21184852640407525\n",
      "â™¯ Epoch: 46/80    |    ğŸ’²Loss: 0.21227338201508036\n",
      "ğŸ’°Validation Loss: 0.28807272389531136\n",
      "ğŸ’°Validation Loss: 0.2716322571112968\n",
      "\n",
      "â™¯ Epoch: 47/80    |    ğŸ’²Loss: 0.1689216699451208\n",
      "â™¯ Epoch: 47/80    |    ğŸ’²Loss: 0.20822418274560778\n",
      "â™¯ Epoch: 47/80    |    ğŸ’²Loss: 0.2120779689160449\n",
      "â™¯ Epoch: 47/80    |    ğŸ’²Loss: 0.21238615489456542\n",
      "â™¯ Epoch: 47/80    |    ğŸ’²Loss: 0.21271161660273324\n",
      "ğŸ’°Validation Loss: 0.29322975128889084\n",
      "ğŸ’°Validation Loss: 0.2667036575846153\n",
      "\n",
      "â™¯ Epoch: 48/80    |    ğŸ’²Loss: 0.2206416353583336\n",
      "â™¯ Epoch: 48/80    |    ğŸ’²Loss: 0.21264266492891135\n",
      "â™¯ Epoch: 48/80    |    ğŸ’²Loss: 0.21125371576708496\n",
      "â™¯ Epoch: 48/80    |    ğŸ’²Loss: 0.2123596481452897\n",
      "â™¯ Epoch: 48/80    |    ğŸ’²Loss: 0.212358090215992\n",
      "ğŸ’°Validation Loss: 0.32077594473958015\n",
      "ğŸ’°Validation Loss: 0.2726628036782293\n",
      "\n",
      "â™¯ Epoch: 49/80    |    ğŸ’²Loss: 0.2681742161512375\n",
      "â™¯ Epoch: 49/80    |    ğŸ’²Loss: 0.20885769010401598\n",
      "â™¯ Epoch: 49/80    |    ğŸ’²Loss: 0.21219514405808934\n",
      "â™¯ Epoch: 49/80    |    ğŸ’²Loss: 0.21286379369563638\n",
      "â™¯ Epoch: 49/80    |    ğŸ’²Loss: 0.21331424453293446\n",
      "ğŸ’°Validation Loss: 0.22503404133021832\n",
      "ğŸ’°Validation Loss: 0.2719957318599566\n",
      "\n",
      "â™¯ Epoch: 50/80    |    ğŸ’²Loss: 0.19557191245257854\n",
      "â™¯ Epoch: 50/80    |    ğŸ’²Loss: 0.20915657937489818\n",
      "â™¯ Epoch: 50/80    |    ğŸ’²Loss: 0.2113039934525813\n",
      "â™¯ Epoch: 50/80    |    ğŸ’²Loss: 0.21075766527115605\n",
      "â™¯ Epoch: 50/80    |    ğŸ’²Loss: 0.21047116162956803\n",
      "ğŸ’°Validation Loss: 0.24875091761350632\n",
      "ğŸ’°Validation Loss: 0.26848593843861085\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 51/80    |    ğŸ’²Loss: 0.1494999323040247\n",
      "â™¯ Epoch: 51/80    |    ğŸ’²Loss: 0.20945160649716854\n",
      "â™¯ Epoch: 51/80    |    ğŸ’²Loss: 0.20956440515983016\n",
      "â™¯ Epoch: 51/80    |    ğŸ’²Loss: 0.20973855817374895\n",
      "â™¯ Epoch: 51/80    |    ğŸ’²Loss: 0.20934578246829516\n",
      "ğŸ’°Validation Loss: 0.19009233079850674\n",
      "ğŸ’°Validation Loss: 0.27230593879329096\n",
      "\n",
      "â™¯ Epoch: 52/80    |    ğŸ’²Loss: 0.2227483168244362\n",
      "â™¯ Epoch: 52/80    |    ğŸ’²Loss: 0.21257155253966847\n",
      "â™¯ Epoch: 52/80    |    ğŸ’²Loss: 0.2117536985894563\n",
      "â™¯ Epoch: 52/80    |    ğŸ’²Loss: 0.21259010345535817\n",
      "â™¯ Epoch: 52/80    |    ğŸ’²Loss: 0.21108783116364419\n",
      "ğŸ’°Validation Loss: 0.2796822525560856\n",
      "ğŸ’°Validation Loss: 0.2694876899961198\n",
      "\n",
      "â™¯ Epoch: 53/80    |    ğŸ’²Loss: 0.19695528224110603\n",
      "â™¯ Epoch: 53/80    |    ğŸ’²Loss: 0.20629194267278556\n",
      "â™¯ Epoch: 53/80    |    ğŸ’²Loss: 0.20838493488228588\n",
      "â™¯ Epoch: 53/80    |    ğŸ’²Loss: 0.20953481839010585\n",
      "â™¯ Epoch: 53/80    |    ğŸ’²Loss: 0.20878246517624344\n",
      "ğŸ’°Validation Loss: 0.20924557745456696\n",
      "ğŸ’°Validation Loss: 0.26690868806499657\n",
      "\n",
      "â™¯ Epoch: 54/80    |    ğŸ’²Loss: 0.1547359973192215\n",
      "â™¯ Epoch: 54/80    |    ğŸ’²Loss: 0.2080182541936341\n",
      "â™¯ Epoch: 54/80    |    ğŸ’²Loss: 0.20943141778217472\n",
      "â™¯ Epoch: 54/80    |    ğŸ’²Loss: 0.20954679682590935\n",
      "â™¯ Epoch: 54/80    |    ğŸ’²Loss: 0.20941593750447332\n",
      "ğŸ’°Validation Loss: 0.2585603594779968\n",
      "ğŸ’°Validation Loss: 0.2703827794383068\n",
      "\n",
      "â™¯ Epoch: 55/80    |    ğŸ’²Loss: 0.19202785938978195\n",
      "â™¯ Epoch: 55/80    |    ğŸ’²Loss: 0.2107013090891708\n",
      "â™¯ Epoch: 55/80    |    ğŸ’²Loss: 0.21270244809525524\n",
      "â™¯ Epoch: 55/80    |    ğŸ’²Loss: 0.21045631633768247\n",
      "â™¯ Epoch: 55/80    |    ğŸ’²Loss: 0.21014941846510568\n",
      "ğŸ’°Validation Loss: 0.31583017110824585\n",
      "ğŸ’°Validation Loss: 0.2711156630833255\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 56/80    |    ğŸ’²Loss: 0.21315933763980865\n",
      "â™¯ Epoch: 56/80    |    ğŸ’²Loss: 0.20904393466466134\n",
      "â™¯ Epoch: 56/80    |    ğŸ’²Loss: 0.20861408141307272\n",
      "â™¯ Epoch: 56/80    |    ğŸ’²Loss: 0.21066520839583042\n",
      "â™¯ Epoch: 56/80    |    ğŸ’²Loss: 0.2095358023731191\n",
      "ğŸ’°Validation Loss: 0.30424731224775314\n",
      "ğŸ’°Validation Loss: 0.26976818340544656\n",
      "\n",
      "â™¯ Epoch: 57/80    |    ğŸ’²Loss: 0.2027426678687334\n",
      "â™¯ Epoch: 57/80    |    ğŸ’²Loss: 0.21501249733316427\n",
      "â™¯ Epoch: 57/80    |    ğŸ’²Loss: 0.21111685427749038\n",
      "â™¯ Epoch: 57/80    |    ğŸ’²Loss: 0.20965809293982396\n",
      "â™¯ Epoch: 57/80    |    ğŸ’²Loss: 0.21054433040934015\n",
      "ğŸ’°Validation Loss: 0.25504519045352936\n",
      "ğŸ’°Validation Loss: 0.2652236134514655\n",
      "\n",
      "â™¯ Epoch: 58/80    |    ğŸ’²Loss: 0.2539158947765827\n",
      "â™¯ Epoch: 58/80    |    ğŸ’²Loss: 0.2083124184593706\n",
      "â™¯ Epoch: 58/80    |    ğŸ’²Loss: 0.20734213444575741\n",
      "â™¯ Epoch: 58/80    |    ğŸ’²Loss: 0.2069999536134278\n",
      "â™¯ Epoch: 58/80    |    ğŸ’²Loss: 0.20834066958498776\n",
      "ğŸ’°Validation Loss: 0.3177534490823746\n",
      "ğŸ’°Validation Loss: 0.2667241687932522\n",
      "\n",
      "â™¯ Epoch: 59/80    |    ğŸ’²Loss: 0.23938501626253128\n",
      "â™¯ Epoch: 59/80    |    ğŸ’²Loss: 0.2090722683190119\n",
      "â™¯ Epoch: 59/80    |    ğŸ’²Loss: 0.2084186109320367\n",
      "â™¯ Epoch: 59/80    |    ğŸ’²Loss: 0.2085956887147108\n",
      "â™¯ Epoch: 59/80    |    ğŸ’²Loss: 0.20825896192425652\n",
      "ğŸ’°Validation Loss: 0.21615122444927692\n",
      "ğŸ’°Validation Loss: 0.27238123648163703\n",
      "\n",
      "â™¯ Epoch: 60/80    |    ğŸ’²Loss: 0.20339177548885345\n",
      "â™¯ Epoch: 60/80    |    ğŸ’²Loss: 0.21170397842358243\n",
      "â™¯ Epoch: 60/80    |    ğŸ’²Loss: 0.210359830914334\n",
      "â™¯ Epoch: 60/80    |    ğŸ’²Loss: 0.20907957163450627\n",
      "â™¯ Epoch: 60/80    |    ğŸ’²Loss: 0.20924760541992443\n",
      "ğŸ’°Validation Loss: 0.2704983353614807\n",
      "ğŸ’°Validation Loss: 0.27182572464099025\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 61/80    |    ğŸ’²Loss: 0.20894357189536095\n",
      "â™¯ Epoch: 61/80    |    ğŸ’²Loss: 0.2092052195958867\n",
      "â™¯ Epoch: 61/80    |    ğŸ’²Loss: 0.20994079874281713\n",
      "â™¯ Epoch: 61/80    |    ğŸ’²Loss: 0.2091835354767319\n",
      "â™¯ Epoch: 61/80    |    ğŸ’²Loss: 0.20951377400464177\n",
      "ğŸ’°Validation Loss: 0.2702058032155037\n",
      "ğŸ’°Validation Loss: 0.26955294644109684\n",
      "\n",
      "â™¯ Epoch: 62/80    |    ğŸ’²Loss: 0.20232634618878365\n",
      "â™¯ Epoch: 62/80    |    ğŸ’²Loss: 0.21712616245529734\n",
      "â™¯ Epoch: 62/80    |    ğŸ’²Loss: 0.20993971453043656\n",
      "â™¯ Epoch: 62/80    |    ğŸ’²Loss: 0.20708827706567473\n",
      "â™¯ Epoch: 62/80    |    ğŸ’²Loss: 0.20713814812714693\n",
      "ğŸ’°Validation Loss: 0.32518257945775986\n",
      "ğŸ’°Validation Loss: 0.2709593033178313\n",
      "\n",
      "â™¯ Epoch: 63/80    |    ğŸ’²Loss: 0.20120599120855331\n",
      "â™¯ Epoch: 63/80    |    ğŸ’²Loss: 0.2111068982630968\n",
      "â™¯ Epoch: 63/80    |    ğŸ’²Loss: 0.21185604684907405\n",
      "â™¯ Epoch: 63/80    |    ğŸ’²Loss: 0.21073559008885262\n",
      "â™¯ Epoch: 63/80    |    ğŸ’²Loss: 0.2093816455360734\n",
      "ğŸ’°Validation Loss: 0.21574145555496216\n",
      "ğŸ’°Validation Loss: 0.26707750684258963\n",
      "\n",
      "â™¯ Epoch: 64/80    |    ğŸ’²Loss: 0.20372743532061577\n",
      "â™¯ Epoch: 64/80    |    ğŸ’²Loss: 0.20758366073933568\n",
      "â™¯ Epoch: 64/80    |    ğŸ’²Loss: 0.21015292252251758\n",
      "â™¯ Epoch: 64/80    |    ğŸ’²Loss: 0.20971571141080406\n",
      "â™¯ Epoch: 64/80    |    ğŸ’²Loss: 0.20971321992046593\n",
      "ğŸ’°Validation Loss: 0.2961873598396778\n",
      "ğŸ’°Validation Loss: 0.2663544807214253\n",
      "\n",
      "â™¯ Epoch: 65/80    |    ğŸ’²Loss: 0.1751280464231968\n",
      "â™¯ Epoch: 65/80    |    ğŸ’²Loss: 0.20569163287003148\n",
      "â™¯ Epoch: 65/80    |    ğŸ’²Loss: 0.20728461521756442\n",
      "â™¯ Epoch: 65/80    |    ğŸ’²Loss: 0.2069488218784382\n",
      "â™¯ Epoch: 65/80    |    ğŸ’²Loss: 0.20867170051594922\n",
      "ğŸ’°Validation Loss: 0.26097482815384865\n",
      "ğŸ’°Validation Loss: 0.27049510380124103\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 66/80    |    ğŸ’²Loss: 0.2036220133304596\n",
      "â™¯ Epoch: 66/80    |    ğŸ’²Loss: 0.2041565489650953\n",
      "â™¯ Epoch: 66/80    |    ğŸ’²Loss: 0.20884003260390677\n",
      "â™¯ Epoch: 66/80    |    ğŸ’²Loss: 0.20894067587819803\n",
      "â™¯ Epoch: 66/80    |    ğŸ’²Loss: 0.2109983229796005\n",
      "ğŸ’°Validation Loss: 0.29718442261219025\n",
      "ğŸ’°Validation Loss: 0.26792062332134436\n",
      "\n",
      "â™¯ Epoch: 67/80    |    ğŸ’²Loss: 0.22703242674469948\n",
      "â™¯ Epoch: 67/80    |    ğŸ’²Loss: 0.2016565074203628\n",
      "â™¯ Epoch: 67/80    |    ğŸ’²Loss: 0.20384092298127823\n",
      "â™¯ Epoch: 67/80    |    ğŸ’²Loss: 0.20407467987697783\n",
      "â™¯ Epoch: 67/80    |    ğŸ’²Loss: 0.2058456254254404\n",
      "ğŸ’°Validation Loss: 0.3301605358719826\n",
      "ğŸ’°Validation Loss: 0.26782612629824937\n",
      "\n",
      "â™¯ Epoch: 68/80    |    ğŸ’²Loss: 0.18940622173249722\n",
      "â™¯ Epoch: 68/80    |    ğŸ’²Loss: 0.20724746771156788\n",
      "â™¯ Epoch: 68/80    |    ğŸ’²Loss: 0.2080760298213407\n",
      "â™¯ Epoch: 68/80    |    ğŸ’²Loss: 0.20811632994030202\n",
      "â™¯ Epoch: 68/80    |    ğŸ’²Loss: 0.20806717459214596\n",
      "ğŸ’°Validation Loss: 0.3291851729154587\n",
      "ğŸ’°Validation Loss: 0.26295671687636635\n",
      "\n",
      "â™¯ Epoch: 69/80    |    ğŸ’²Loss: 0.18547015637159348\n",
      "â™¯ Epoch: 69/80    |    ğŸ’²Loss: 0.20306811341554812\n",
      "â™¯ Epoch: 69/80    |    ğŸ’²Loss: 0.20599734444004386\n",
      "â™¯ Epoch: 69/80    |    ğŸ’²Loss: 0.20740767797312865\n",
      "â™¯ Epoch: 69/80    |    ğŸ’²Loss: 0.20795448025005714\n",
      "ğŸ’°Validation Loss: 0.2162478230893612\n",
      "ğŸ’°Validation Loss: 0.26681636321810215\n",
      "\n",
      "â™¯ Epoch: 70/80    |    ğŸ’²Loss: 0.19365644454956055\n",
      "â™¯ Epoch: 70/80    |    ğŸ’²Loss: 0.20634144365713739\n",
      "â™¯ Epoch: 70/80    |    ğŸ’²Loss: 0.20887749386367513\n",
      "â™¯ Epoch: 70/80    |    ğŸ’²Loss: 0.2072268134335743\n",
      "â™¯ Epoch: 70/80    |    ğŸ’²Loss: 0.2067382598360838\n",
      "ğŸ’°Validation Loss: 0.20758157223463058\n",
      "ğŸ’°Validation Loss: 0.2688362145114063\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 71/80    |    ğŸ’²Loss: 0.20569773763418198\n",
      "â™¯ Epoch: 71/80    |    ğŸ’²Loss: 0.2123859508866721\n",
      "â™¯ Epoch: 71/80    |    ğŸ’²Loss: 0.21119247456150714\n",
      "â™¯ Epoch: 71/80    |    ğŸ’²Loss: 0.2106911755658909\n",
      "â™¯ Epoch: 71/80    |    ğŸ’²Loss: 0.20949395829370418\n",
      "ğŸ’°Validation Loss: 0.2534487396478653\n",
      "ğŸ’°Validation Loss: 0.27067695622618243\n",
      "\n",
      "â™¯ Epoch: 72/80    |    ğŸ’²Loss: 0.20570825785398483\n",
      "â™¯ Epoch: 72/80    |    ğŸ’²Loss: 0.21195109275234217\n",
      "â™¯ Epoch: 72/80    |    ğŸ’²Loss: 0.21272138799934542\n",
      "â™¯ Epoch: 72/80    |    ğŸ’²Loss: 0.21119477321390695\n",
      "â™¯ Epoch: 72/80    |    ğŸ’²Loss: 0.2092459949193304\n",
      "ğŸ’°Validation Loss: 0.27360454574227333\n",
      "ğŸ’°Validation Loss: 0.2700418196618557\n",
      "\n",
      "â™¯ Epoch: 73/80    |    ğŸ’²Loss: 0.16100750863552094\n",
      "â™¯ Epoch: 73/80    |    ğŸ’²Loss: 0.20385222763081293\n",
      "â™¯ Epoch: 73/80    |    ğŸ’²Loss: 0.20605366985633303\n",
      "â™¯ Epoch: 73/80    |    ğŸ’²Loss: 0.20626671143197933\n",
      "â™¯ Epoch: 73/80    |    ğŸ’²Loss: 0.20775436387023427\n",
      "ğŸ’°Validation Loss: 0.21542589738965034\n",
      "ğŸ’°Validation Loss: 0.26701920556992587\n",
      "\n",
      "â™¯ Epoch: 74/80    |    ğŸ’²Loss: 0.20034540817141533\n",
      "â™¯ Epoch: 74/80    |    ğŸ’²Loss: 0.20687485065790687\n",
      "â™¯ Epoch: 74/80    |    ğŸ’²Loss: 0.2072170047293329\n",
      "â™¯ Epoch: 74/80    |    ğŸ’²Loss: 0.20749658073895794\n",
      "â™¯ Epoch: 74/80    |    ğŸ’²Loss: 0.20673391554374573\n",
      "ğŸ’°Validation Loss: 0.2237606644630432\n",
      "ğŸ’°Validation Loss: 0.2731486283666869\n",
      "\n",
      "â™¯ Epoch: 75/80    |    ğŸ’²Loss: 0.21205130219459534\n",
      "â™¯ Epoch: 75/80    |    ğŸ’²Loss: 0.20459171694399106\n",
      "â™¯ Epoch: 75/80    |    ğŸ’²Loss: 0.2050797192991447\n",
      "â™¯ Epoch: 75/80    |    ğŸ’²Loss: 0.20721095797615094\n",
      "â™¯ Epoch: 75/80    |    ğŸ’²Loss: 0.20816632620339975\n",
      "ğŸ’°Validation Loss: 0.2949207052588463\n",
      "ğŸ’°Validation Loss: 0.2682117712822291\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â™¯ Epoch: 76/80    |    ğŸ’²Loss: 0.17539327964186668\n",
      "â™¯ Epoch: 76/80    |    ğŸ’²Loss: 0.20532034084864773\n",
      "â™¯ Epoch: 76/80    |    ğŸ’²Loss: 0.20522581317012584\n",
      "â™¯ Epoch: 76/80    |    ğŸ’²Loss: 0.20584820718365254\n",
      "â™¯ Epoch: 76/80    |    ğŸ’²Loss: 0.20700747049192983\n",
      "ğŸ’°Validation Loss: 0.3660261444747448\n",
      "ğŸ’°Validation Loss: 0.26407648693069374\n",
      "\n",
      "â™¯ Epoch: 77/80    |    ğŸ’²Loss: 0.22681909427046776\n",
      "â™¯ Epoch: 77/80    |    ğŸ’²Loss: 0.20885552362640306\n",
      "â™¯ Epoch: 77/80    |    ğŸ’²Loss: 0.20697888296875935\n",
      "â™¯ Epoch: 77/80    |    ğŸ’²Loss: 0.20772974508075026\n",
      "â™¯ Epoch: 77/80    |    ğŸ’²Loss: 0.20864333982516703\n",
      "ğŸ’°Validation Loss: 0.21104083210229874\n",
      "ğŸ’°Validation Loss: 0.26632087432438195\n",
      "\n",
      "â™¯ Epoch: 78/80    |    ğŸ’²Loss: 0.26983895897865295\n",
      "â™¯ Epoch: 78/80    |    ğŸ’²Loss: 0.2057887102929082\n",
      "â™¯ Epoch: 78/80    |    ğŸ’²Loss: 0.20915772675059327\n",
      "â™¯ Epoch: 78/80    |    ğŸ’²Loss: 0.20729351574338453\n",
      "â™¯ Epoch: 78/80    |    ğŸ’²Loss: 0.20721071490093582\n",
      "ğŸ’°Validation Loss: 0.406842902302742\n",
      "ğŸ’°Validation Loss: 0.27426794114163017\n",
      "\n",
      "â™¯ Epoch: 79/80    |    ğŸ’²Loss: 0.2449817694723606\n",
      "â™¯ Epoch: 79/80    |    ğŸ’²Loss: 0.20871324248907\n",
      "â™¯ Epoch: 79/80    |    ğŸ’²Loss: 0.20614413596893572\n",
      "â™¯ Epoch: 79/80    |    ğŸ’²Loss: 0.20804363749364385\n",
      "â™¯ Epoch: 79/80    |    ğŸ’²Loss: 0.20703841119707375\n",
      "ğŸ’°Validation Loss: 0.300577811896801\n",
      "ğŸ’°Validation Loss: 0.2705818192461635\n",
      "\n",
      "â™¯ Epoch: 80/80    |    ğŸ’²Loss: 0.2383762151002884\n",
      "â™¯ Epoch: 80/80    |    ğŸ’²Loss: 0.2062362108730001\n",
      "â™¯ Epoch: 80/80    |    ğŸ’²Loss: 0.20582856520065176\n",
      "â™¯ Epoch: 80/80    |    ğŸ’²Loss: 0.2065266636648893\n",
      "â™¯ Epoch: 80/80    |    ğŸ’²Loss: 0.2071271587344365\n",
      "ğŸ’°Validation Loss: 0.3134002424776554\n",
      "ğŸ’°Validation Loss: 0.268727813856584\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Save checkpoint ..... â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\nâ•‘ Start training ..... â•‘\\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "trainer = Trainer(ckptroot,\n",
    "                  model,\n",
    "                  device,\n",
    "                  epochs,\n",
    "                  criterion,\n",
    "                  optimizer,\n",
    "                  scheduler,\n",
    "                  start_epoch,\n",
    "                  trainloader,\n",
    "                  validationloader)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
